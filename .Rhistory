b.true<- -3
fig0 +
geom_abline(slope = b.true,
intercept = a.comp(b.true,
mean_x,mean_y),
color="blue",size=2,alpha=0.1) -> fig0
fig0
fig0 +
geom_smooth(data=c1995,method="lm",se=FALSE,color="black")
fig0+
geom_point(data=(CigarettesSW_temp %>%
filter(state %in% c("GA","MA"))),
aes(x=rprice,y=packs,color=state),
size=4)->fig1
fig1
knitr::opts_chunk$set(echo = FALSE, message=FALSE)
library(AER)
library(dplyr)
library(magrittr)
data("CigarettesSW")
CigarettesSW %>% filter(year=="1995") %>%
mutate(rprice=log(price/cpi),
packs=log(packs)) -> CigarettesSW_temp
library(ggplot2)
library(cowplot)
CigarettesSW_temp %>%
ggplot(aes(y=packs,x=rprice)) +
geom_point() -> fig0
# 計算通過中心點的直線方程式
a.comp<-function(b,mean.x,mean.y){
a<- mean.y-b*mean.x
return(a)
}
b.true<- -3
fig0 +
geom_abline(slope = b.true,
intercept = a.comp(b.true,
mean_x,mean_y),
color="blue",size=2,alpha=0.1) -> fig0
fig0
fig0 +
geom_smooth(data=c1995,method="lm",se=FALSE,color="black")
fig0+
geom_point(data=(CigarettesSW_temp %>%
filter(state %in% c("GA","MA"))),
aes(x=rprice,y=packs,color=state),
size=4)->fig1
fig1
mean_x<-mean(c1995$rprice)
mean_y<-mean(c1995$packs)
fig1
fig0
View(CigarettesSW_temp)
View(c1995)
c1995 %>%
ggplot(aes(y=packs,x=rprice,fill=rincome)) +
geom_point()
c1995 %>%
ggplot(aes(y=packs,x=rprice,color=rincome)) +
geom_point()
c1995 %>%
ggplot(aes(y=packs,x=rprice,size=rincome)) +
geom_point()
c1995 %>%
ggplot(aes(y=packs,x=rprice,alpha=rincome)) +
geom_point()
c1995 %>%
ggplot(aes(y=packs,x=rprice,alpha=rincome)) +
geom_point(size=2)
c1995 %>%
ggplot(aes(y=packs,x=rprice,alpha=rincome)) +
geom_point(size=3)
knitr::opts_chunk$set(echo = FALSE, message=FALSE)
library(AER)
library(dplyr)
library(magrittr)
data("CigarettesSW")
CigarettesSW %>% filter(year=="1995") %>%
mutate(rprice=log(price/cpi),
packs=log(packs)) -> CigarettesSW_temp
c1995<-CigarettesSW_temp
library(ggplot2)
library(cowplot)
CigarettesSW_temp %>%
ggplot(aes(y=packs,x=rprice)) +
geom_point() -> fig0
# 計算通過中心點的直線方程式
a.comp<-function(b,mean.x,mean.y){
a<- mean.y-b*mean.x
return(a)
}
mean_x<-mean(c1995$rprice)
mean_y<-mean(c1995$packs)
b.true<- -3
fig0 +
geom_abline(slope = b.true,
intercept = a.comp(b.true,
mean_x,mean_y),
color="blue",size=2,alpha=0.1) -> fig0
fig0
fig0 +
geom_smooth(data=c1995,method="lm",se=FALSE,color="black")
fig0+
geom_point(data=(CigarettesSW_temp %>%
filter(state %in% c("GA","MA"))),
aes(x=rprice,y=packs,color=state),
size=4)->fig1
fig1
c1995 %>%
ggplot(aes(y=packs,x=rprice,alpha=rincome)) +
geom_point(size=3)
c1995 %<>% mutate(rincome=(income/cpi)/population)
ggplot(aes(y=packs,x=rprice,alpha=rincome)) +
geom_point(size=3)
c1995 %>%
ggplot(aes(y=packs,x=rprice,alpha=rincome)) +
geom_point(size=3)
c1995 %<>% mutate(rincome=(income/cpi)/population)
c1995 %>%
ggplot(aes(y=packs,x=rprice,alpha=rincome)) +
geom_point(size=4)
bookdown::publish_book()
q()
knitr::opts_chunk$set(warning = FALSE, message = FALSE)
library(keras)
dataset <- dataset_boston_housing()
c(c(train_data, train_targets), c(test_data, test_targets)) %<-% dataset
str(train_data)
str(test_data)
str(train_targets)
mean <- apply(train_data, 2, mean)
std <- apply(train_data, 2, sd)
train_data <- scale(train_data, center = mean, scale = std)
test_data <- scale(test_data, center = mean, scale = std)
# Because we will need to instantiate the same model multiple times,
# we use a function to construct it.
build_model <- function() {
model <- keras_model_sequential() %>%
layer_dense(units = 64, activation = "relu",
input_shape = dim(train_data)[[2]]) %>%
layer_dense(units = 64, activation = "relu") %>%
layer_dense(units = 1)
model %>% compile(
optimizer = "rmsprop",
loss = "mse",
metrics = c("mae")
)
}
k <- 4
indices <- sample(1:nrow(train_data))
folds <- cut(indices, breaks = k, labels = FALSE)
num_epochs <- 100
all_scores <- c()
for (i in 1:k) {
cat("processing fold #", i, "\n")
# Prepare the validation data: data from partition # k
val_indices <- which(folds == i, arr.ind = TRUE)
val_data <- train_data[val_indices,]
val_targets <- train_targets[val_indices]
# Prepare the training data: data from all other partitions
partial_train_data <- train_data[-val_indices,]
partial_train_targets <- train_targets[-val_indices]
# Build the Keras model (already compiled)
model <- build_model()
# Train the model (in silent mode, verbose=0)
model %>% fit(partial_train_data, partial_train_targets,
epochs = num_epochs, batch_size = 1, verbose = 0)
# Evaluate the model on the validation data
results <- model %>% evaluate(val_data, val_targets, verbose = 0)
all_scores <- c(all_scores, results$mean_absolute_error)
}
q()
devtools::install_github("rstudio/keras")
👍 1
q()
knitr::opts_chunk$set(warning = FALSE, message = FALSE)
library(keras)
imdb <- dataset_imdb(num_words = 10000)
c(c(train_data, train_labels), c(test_data, test_labels)) %<-% imdb
vectorize_sequences <- function(sequences, dimension = 10000) {
# Create an all-zero matrix of shape (len(sequences), dimension)
results <- matrix(0, nrow = length(sequences), ncol = dimension)
for (i in 1:length(sequences))
# Sets specific indices of results[i] to 1s
results[i, sequences[[i]]] <- 1
results
}
# Our vectorized training data
x_train <- vectorize_sequences(train_data)
# Our vectorized test data
x_test <- vectorize_sequences(test_data)
# Our vectorized labels
y_train <- as.numeric(train_labels)
y_test <- as.numeric(test_labels)
original_model <- keras_model_sequential() %>%
layer_dense(units = 16, activation = "relu", input_shape = c(10000)) %>%
layer_dense(units = 16, activation = "relu") %>%
layer_dense(units = 1, activation = "sigmoid")
original_model %>% compile(
optimizer = "rmsprop",
loss = "binary_crossentropy",
metrics = c("accuracy")
)
smaller_model <- keras_model_sequential() %>%
layer_dense(units = 4, activation = "relu", input_shape = c(10000)) %>%
layer_dense(units = 4, activation = "relu") %>%
layer_dense(units = 1, activation = "sigmoid")
smaller_model %>% compile(
optimizer = "rmsprop",
loss = "binary_crossentropy",
metrics = c("accuracy")
)
original_hist <- original_model %>% fit(
x_train, y_train,
epochs = 20,
batch_size = 512,
validation_data = list(x_test, y_test)
)
smaller_model_hist <- smaller_model %>% fit(
x_train, y_train,
epochs = 20,
batch_size = 512,
validation_data = list(x_test, y_test)
)
library(ggplot2)
library(tidyr)
plot_training_losses <- function(losses) {
loss_names <- names(losses)
losses <- as.data.frame(losses)
losses$epoch <- seq_len(nrow(losses))
losses %>%
gather(model, loss, loss_names[[1]], loss_names[[2]]) %>%
ggplot(aes(x = epoch, y = loss, colour = model)) +
geom_point()
}
plot_training_losses(losses = list(
original_model = original_hist$metrics$val_loss,
smaller_model = smaller_model_hist$metrics$val_loss
))
bigger_model <- keras_model_sequential() %>%
layer_dense(units = 512, activation = "relu", input_shape = c(10000)) %>%
layer_dense(units = 512, activation = "relu") %>%
layer_dense(units = 1, activation = "sigmoid")
bigger_model %>% compile(
optimizer = "rmsprop",
loss = "binary_crossentropy",
metrics = c('acc')
)
bigger_model_hist <- bigger_model %>% fit(
x_train, y_train,
epochs = 20,
batch_size = 512,
validation_data = list(x_test, y_test)
)
q()
q()
knit_with_parameters('~/Desktop/GitHub/Econometric-Analysis-eBook/bookdown/01-OLS.Rmd')
q()
knitr::opts_chunk$set(echo = TRUE, message=FALSE)
library("AER")
library("ggplot2")
library("dplyr")
library("knitr")
data("Journals")
Journals %>% mutate(citeprice=price/citations) -> journals
summary(journals)
library(psych)
journals %>%
select(citeprice,subs) %>%
pairs.panels()
journals %>%
select(citeprice,subs) %>%
mutate_all(log) %>%
pairs.panels()
knitr::opts_chunk$set(echo = TRUE, message=FALSE)
library("AER")
library("ggplot2")
library("dplyr")
library("knitr")
data("Journals")
Journals %>% mutate(citeprice=price/citations) -> journals
summary(journals)
library(psych)
journals %>%
select(citeprice,subs) %>%
pairs.panels()
journals %>%
select(citeprice,subs) %>%
mutate_all(log) %>%
pairs.panels()
# 判斷變數是否為數值類別
is_numeric<-function(x) all(is.numeric(x))
# 計算數數與citeprice的相關係數
cor_citeprice<-function(x) cor(x,journals$citeprice)
journals %>%
select_if(is_numeric) %>%
summarise_all(cor_citeprice) %>%
kable()
journals %>%
lm(log(subs)~log(citeprice),data=.)
journals %>%
lm(log(subs)~log(citeprice)+citations,data=.)
journals %>%
lm(log(subs)~log(citeprice),data=.) -> model_1
journals %>%
lm(log(subs)~log(citeprice)+citations,data=.) -> model_2
library(sandwich)
library(lmtest)
library(stargazer)
robust_se<-function(model,hctype="HC1"){
require(expm)
cov <- vcovHC(model, type = hctype)
robust.se <- diag(sqrtm(cov))
return(robust.se)
}
stargazer(model_1, model_2,
se=list(robust_se(model_1), robust_se(model_2)),
type="html",
align=TRUE)
View(journals)
journals %>%
lm(log(subs)~log(citeprice),data=.) -> model_1
journals %>%
lm(log(subs)~log(citeprice)+foundingyear,data=.) -> model_2
library(sandwich)
library(lmtest)
library(stargazer)
robust_se<-function(model,hctype="HC1"){
require(expm)
cov <- vcovHC(model, type = hctype)
robust.se <- diag(sqrtm(cov))
return(robust.se)
}
stargazer(model_1, model_2,
se=list(robust_se(model_1), robust_se(model_2)),
type="html",
align=TRUE)
knitr::opts_chunk$set(echo = TRUE, message=FALSE)
library("AER")
library("ggplot2")
library("dplyr")
library("knitr")
data("Journals")
Journals %>% mutate(citeprice=price/citations) -> journals
summary(journals)
library(psych)
journals %>%
select(citeprice,subs) %>%
pairs.panels()
journals %>%
select(citeprice,subs) %>%
mutate_all(log) %>%
pairs.panels()
# 判斷變數是否為數值類別
is_numeric<-function(x) all(is.numeric(x))
# 計算數數與citeprice的相關係數
cor_citeprice<-function(x) cor(x,journals$citeprice)
journals %>%
select_if(is_numeric) %>%
summarise_all(cor_citeprice) %>%
kable()
journals %>%
lm(log(subs)~log(citeprice),data=.)
journals %>%
lm(log(subs)~log(citeprice)+foundingyear,data=.)
journals %>%
lm(log(subs)~log(citeprice),data=.) -> model_1
journals %>%
lm(log(subs)~log(citeprice)+foundingyear,data=.) -> model_2
library(sandwich)
library(lmtest)
library(stargazer)
coeftest(model_1, vcov = hc1) -> model_1_coeftest
knitr::opts_chunk$set(echo = TRUE, message=FALSE)
library("AER")
library("ggplot2")
library("dplyr")
library("knitr")
data("Journals")
Journals %>% mutate(citeprice=price/citations) -> journals
summary(journals)
library(psych)
journals %>%
select(citeprice,subs) %>%
pairs.panels()
journals %>%
select(citeprice,subs) %>%
mutate_all(log) %>%
pairs.panels()
# 判斷變數是否為數值類別
is_numeric<-function(x) all(is.numeric(x))
# 計算數數與citeprice的相關係數
cor_citeprice<-function(x) cor(x,journals$citeprice)
journals %>%
select_if(is_numeric) %>%
summarise_all(cor_citeprice) %>%
kable()
journals %>%
lm(log(subs)~log(citeprice),data=.)
journals %>%
lm(log(subs)~log(citeprice)+foundingyear,data=.)
journals %>%
lm(log(subs)~log(citeprice),data=.) -> model_1
journals %>%
lm(log(subs)~log(citeprice)+foundingyear,data=.) -> model_2
library(sandwich)
library(lmtest)
library(stargazer)
hc1 <- function(x) vcovHC(x, type = "HC1")
coeftest(model_1, vcov = hc1) -> model_1_coeftest
coeftest(model_2, vcov = hc1) -> model_2_coeftest
robust_se<-function(model,hctype="HC1"){
require(expm)
cov <- vcovHC(model, type = hctype)
robust.se <- diag(sqrtm(cov))
return(robust.se)
}
stargazer(model_1, model_2,
se=list(robust_se(model_1), robust_se(model_2)),
type="html",
align=TRUE)
model_1_coeftest
model_1_coeftest[,"Std. Error"]
knitr::opts_chunk$set(echo = TRUE, message=FALSE)
library("AER")
library("ggplot2")
library("dplyr")
library("knitr")
data("Journals")
Journals %>% mutate(citeprice=price/citations) -> journals
summary(journals)
library(psych)
journals %>%
select(citeprice,subs) %>%
pairs.panels()
journals %>%
select(citeprice,subs) %>%
mutate_all(log) %>%
pairs.panels()
# 判斷變數是否為數值類別
is_numeric<-function(x) all(is.numeric(x))
# 計算數數與citeprice的相關係數
cor_citeprice<-function(x) cor(x,journals$citeprice)
journals %>%
select_if(is_numeric) %>%
summarise_all(cor_citeprice) %>%
kable()
journals %>%
lm(log(subs)~log(citeprice),data=.)
journals %>%
lm(log(subs)~log(citeprice)+foundingyear,data=.)
journals %>%
lm(log(subs)~log(citeprice),data=.) -> model_1
journals %>%
lm(log(subs)~log(citeprice)+foundingyear,data=.) -> model_2
library(sandwich)
library(lmtest)
library(stargazer)
hc1 <- function(x) vcovHC(x, type = "HC1")
coeftest(model_1, vcov = hc1) -> model_1_coeftest
coeftest(model_2, vcov = hc1) -> model_2_coeftest
robust_se<-function(model,hctype="HC1"){
require(expm)
cov <- vcovHC(model, type = hctype)
robust.se <- diag(sqrtm(cov))
return(robust.se)
}
stargazer(model_1, model_2,
se=list(model_1_coeftest[,"Std. Error"], model_2_coeftest[,2]),
type="html",
align=TRUE)
model_1$df.residual
coeftest(model_1, type="HC1") -> model_1_coeftest
stargazer(model_1, model_2,
se=list(model_1_coeftest[,"Std. Error"], model_2_coeftest[,2]),
type="html",
align=TRUE)
coeftest(model_2, type="HC1") -> model_2_coeftest
bookdown::publish_book()
q()
bookdown::publish_book()
bookdown::publish_book()
bookdown::publish_book()
q()
q()
q()
bookdown::publish_book()
bookdown::publish_book()
bookdown::publish_book()
q()
klippy::klippy()
install.packages("klippy")
devtools::install_github("RLesur/klippy")
klippy::klippy()
bookdown::publish_book()
q(
)
bookdown::publish_book()
bookdown::publish_book()
bookdown::publish_book()
q()
bookdown::publish_book()
q()
knitr::opts_chunk$set(echo = TRUE, message=FALSE)
klippy::klippy()
library("AER")
library("ggplot2")
library("dplyr")
library("knitr")
data("Journals")
bookdown::publish_book()
bookdown::publish_book()
